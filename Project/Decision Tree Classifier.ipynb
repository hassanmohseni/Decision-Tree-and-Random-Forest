{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "361e9815-51d9-443b-ab5a-9d7e8e9ab825",
   "metadata": {},
   "source": [
    "Decision Tree Classifier Algorithm :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b6890-d5c7-4491-aa68-effc4a3cfa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neccesary Library :\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073a8bc-a577-4de9-8a58-6a3a09813aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Entropy :\n",
    "def entropy(y):\n",
    "    proportions = np.bincount(y) / len(y)\n",
    "    return -np.sum([p * np.log2(p) for p in proportions if p > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704a64b-4786-4f4e-aa82-d72d94c32909",
   "metadata": {},
   "source": [
    "Create bestest Decision Tree :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a86866a-35ef-4511-9236-c5844f731b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_decision_stump(X ,y):\n",
    "\n",
    "    \n",
    "    best_gain =-1\n",
    "    best_feature =None\n",
    "    best_threshold =None\n",
    "    best_value_left =None\n",
    "    best_value_right =None\n",
    "\n",
    "     #این حلقه بر روی هر کدام از فیچر های ورودی حرکت میکند و در اینده عملیات هایی را روی هر کدام انجام میدهیم\n",
    "    for feature_index in range(X.shape[1]):\n",
    "        #این دستور مقادیر منحصر به فرد یک فیچر را در قالب یک ارایه بر می گرداند\n",
    "        thresholds =np.unique(X[: ,feature_index])\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            left_mask =X[: ,feature_index] <=threshold\n",
    "            right_mask =~left_mask\n",
    "            left_y ,right_y =y[left_mask] ,y[right_mask]\n",
    "            \n",
    "            if len(left_y) >0 and len(right_y) >0:\n",
    "              #محاسبه وزنها \n",
    "              left_weight =len(left_y) /len(y)\n",
    "              right_weight=1 -left_weight\n",
    "              gain = entropy(y) - (left_weight * entropy(left_y) + right_weight * entropy(right_y))\n",
    "                \n",
    "              if gain > best_gain:\n",
    "                  best_gain = gain\n",
    "                  best_feature = feature_index\n",
    "                  best_threshold = threshold\n",
    "                  best_value_left = np.bincount(left_y).argmax()\n",
    "                  best_value_right = np.bincount(right_y).argmax()\n",
    "\n",
    "\n",
    "\n",
    "    return best_feature, best_threshold, best_value_left, best_value_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66723ce3-bf96-407e-8769-bd248de74572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction with DTS :\n",
    "def predict(X, feature, threshold, value_left, value_right):\n",
    "    return np.where(X[:, feature] <= threshold, value_left, value_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86742936-e177-4488-a77f-109a4177ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing DataSet :\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672586e-9a65-4933-9aef-b6135fea490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divided DataSet to Train Set and TestSet :\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.flatten(), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6790774-6075-49de-abaf-ae6184e754c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Best Parameter for DTS:\n",
    "best_feature, best_threshold, value_left, value_right = best_decision_stump(X_train, y_train)\n",
    "print(\"best_feature :\" ,best_feature)\n",
    "print(\"best_threshold :\" ,best_threshold)\n",
    "print(\"value_left :\" ,value_left)\n",
    "print(\"value_right :\" ,value_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514aafc8-35f5-486c-9e80-0cb8537c20b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(X_test, best_feature, best_threshold, value_left, value_right)\n",
    "print(\"Y_test      :\" ,y_test)\n",
    "print(\"predictions :\" ,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2931de2f-b258-4a54-9cef-5295d0d6a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Model :\n",
    "print(f\"Decision Stump Accuracy: {accuracy_score(y_test, predictions):.3f}\")\n",
    "print(f\"Decision Stump F1-Score: {f1_score(y_test, predictions, average='weighted'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40efa939-6e8c-4620-91f0-77a437b44a19",
   "metadata": {},
   "source": [
    "                                                     Using Scikit-learn's Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7249621-0f9d-45a4-9cc1-de0796d3e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "dt_sklearn = DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "dt_sklearn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4637c05a-410c-42eb-9033-fd3013637da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_skl_predictions = dt_sklearn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7afa88-db17-4043-b377-285be1ca04d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sklearn DT Accuracy: {accuracy_score(y_test, dt_skl_predictions):.3f}\")\n",
    "print(f\"Sklearn DT F1-Score: {f1_score(y_test, dt_skl_predictions, average='weighted'):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e898c-ea85-42e4-a240-538d11bfe29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(10 ,6))\n",
    "plt.title(\"Decision Tree Visualization - Sklearn\")\n",
    "\n",
    "plot_tree(dt_sklearn\n",
    "         ,feature_names =list(iris.feature_names)\n",
    "         ,class_names=list(iris.target_names)\n",
    "         ,filled=True\n",
    "         ,rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f721cc-52dc-4ead-ae8a-a65ecc670b94",
   "metadata": {},
   "source": [
    "In the plot above, you can see the decision rules that have been made for splitting the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f6e6b-4652-4fcb-90d1-0218ae721569",
   "metadata": {},
   "source": [
    "                                                        ((Random Forest Algorithm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee58b09-c4dd-4bf8-b0da-1b9b6cb8b9be",
   "metadata": {},
   "source": [
    "Quick Review:\n",
    "\n",
    "1) Each tree is trained on random subsets of the data and features, and their predictions are averaged for better performance.\n",
    "2) It’s robust, reduces variance, and works well for both classification and regression.\n",
    "\n",
    "Steps to Create a Random Forest:\n",
    "A  :Bagging Randomly sample subsets of the data (with replacement) for each tree.\n",
    "B  :For each tree, randomly select a subset of features at each split.\n",
    "C  :Train a decision tree on each sampled dataset.\n",
    "D  :Repeat steps 1–3 to build multiple decision trees.\n",
    "E  :Aggregating: For predictions, aggregate the outputs of all the trees (e.g., majority vote for classification or averaging for regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a9f30-d6ba-4f7b-a9db-b3d4b8b2c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier  # درخت تصمیم پایه\n",
    "\n",
    "def bootstrap_samples(X, y):\n",
    "    \"\"\"\n",
    "    Applies bootstrap resampling to the dataset.\n",
    "    \"\"\"\n",
    "    return resample(X, y, n_samples=len(X), replace=True)\n",
    "\n",
    "def fit_random_forest(X, y, n_trees=7):\n",
    "    \"\"\"\n",
    "    Fits a random forest to the dataset (X, y).\n",
    "    \"\"\"\n",
    "    trees = []\n",
    "    for _ in range(n_trees):\n",
    "        stump = DecisionTreeClassifier(max_depth=1)  # درخت تصمیم با عمق 1\n",
    "        X_sample, y_sample = bootstrap_samples(X, y)\n",
    "        stump.fit(X_sample, y_sample)\n",
    "        trees.append(stump)\n",
    "    return trees\n",
    "\n",
    "def predict_random_forest(trees, X):\n",
    "    \"\"\"\n",
    "    Predicts class labels for samples in X.\n",
    "    \"\"\"\n",
    "    stump_predictions = np.array([tree.predict(X) for tree in trees])\n",
    "    return majority_vote(stump_predictions)\n",
    "\n",
    "def majority_vote(predictions):\n",
    "    \"\"\"\n",
    "    Returns the majority vote of the predictions.\n",
    "    \"\"\"\n",
    "    return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d985843-4c0b-4be7-8c6b-ee054b5c2235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# بارگذاری داده‌های سرطان سینه\n",
    "breast_cancer = load_breast_cancer()\n",
    "X, y = breast_cancer.data, breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b195c-1936-4c69-b6f7-6959ee08234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# تقسیم داده‌ها به مجموعه‌های آموزشی و تست\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# آموزش مدل Random Forest\n",
    "trees = fit_random_forest(X_train, y_train)\n",
    "\n",
    "# پیش‌بینی با مدل Random Forest\n",
    "rf_custom_predictions = predict_random_forest(trees, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912bd0f-8580-4d13-b290-e194ebb7b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# نمایش نتایج\n",
    "print(f\"Custom RF Accuracy: {accuracy_score(y_test, rf_custom_predictions):.3f}\")\n",
    "print(f\"Custom RF F1-Score: {f1_score(y_test, rf_custom_predictions, average='weighted'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a1e5b-8b0e-44c2-a2ee-f9c7b3718dc8",
   "metadata": {},
   "source": [
    "Using Scikit-learn's Random Forest Classifier :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1168f283-0e41-4b22-9abf-bc2340db27c8",
   "metadata": {},
   "source": [
    "After implementing a custom Random Forest from scratch, we will now compare the results by utilizing the Scikit-learn library,\n",
    "which provides a highly optimized implementation of random forests.\n",
    "This allows us to observe the behavior of random forests without dealing with the complexities of manually building one.\n",
    "We’ll also visualize the decision trees used in the random forest to gain insight into how it makes decisions.\n",
    "Make sure to try different combinations of hyperparameters (n_estimators, max_depth, min_samples, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710db69c-4b1e-4fec-be64-4eff7e68ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47123dcb-f634-4de3-b58e-3e46328c0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_sklearn =RandomForestClassifier(n_estimators=7 ,\n",
    "                                   max_depth= 1 ,\n",
    "                                   criterion=\"entropy\" ,\n",
    "                                   random_state =42)\n",
    "rf_sklearn.fit(X_train ,y_train.ravel())\n",
    "rf_skl_predictions =rf_sklearn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39215da-54e9-4bf7-a9c3-5646117e71b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sklearn RF Accuracy: {accuracy_score(y_test, rf_skl_predictions):.3f}\")\n",
    "print(f\"Sklearn RF F1-Score: {f1_score(y_test, rf_skl_predictions, average='weighted'):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7dd600-73e2-4b84-b53f-551d216f6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, tree in enumerate(rf_sklearn.estimators_):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plot_tree(tree, filled=True, feature_names=list(breast_cancer.feature_names), class_names=list(breast_cancer.target_names))\n",
    "    plt.title(f\"Random Forest Visualization - Tree {idx + 1}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06ef2f-7581-47e4-ad9f-4def1c3a08ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now choose a random sample to illustrate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab268a-6905-4c27-8f0e-685d215f01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 112\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.DataFrame(X_test[112].reshape(1, -1), columns=breast_cancer.feature_names).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d9ab7-39ed-44dd-95f7-d9956d05971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = [tree.predict(X_test[112].reshape(1, -1)) for tree in rf_sklearn.estimators_]\n",
    "final_prediction = rf_sklearn.predict(X_test[sample_idx].reshape(1, -1))[0]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter([range(1, len(rf_sklearn.estimators_) + 1)], votes, s=100, alpha=0.7, label='Votes')\n",
    "plt.axhline(y=final_prediction, color='r', linestyle='--', label='Final Prediction')\n",
    "plt.yticks([0, 1], ['Class 0', 'Class 1'])\n",
    "plt.xlabel('Decision Trees')\n",
    "plt.ylabel('Votes')\n",
    "plt.title(f'Random Forest: Votes from Each DT for Sample #{sample_idx + 1}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0022531-0167-4c28-ab90-b23cf0e12788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
